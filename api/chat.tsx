import { VercelRequest, VercelResponse } from "@vercel/node";
import OpenAI from "openai";

// âœ… **ØªØ£ÙƒØ¯ Ù…Ù† ØªÙˆÙØ± Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø¨ÙŠØ¦Ø©**
const openaiApiKey = process.env.VITE_OPENAI_API_KEY;
const assistantId = process.env.VITE_ASSISTANT_ID;

if (!openaiApiKey || !assistantId) {
  throw new Error(
    "âŒ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ VITE_OPENAI_API_KEY Ø£Ùˆ VITE_ASSISTANT_ID ÙÙŠ Ø§Ù„Ø¨ÙŠØ¦Ø©!"
  );
}

// âœ… **ØªÙ‡ÙŠØ¦Ø© OpenAI API**
const openai = new OpenAI({ apiKey: openaiApiKey });

export default async function handler(req: VercelRequest, res: VercelResponse) {
  if (req.method !== "POST") {
    return res.status(405).json({ error: "âŒ Method Not Allowed" });
  }

  const { message } = req.body;

  if (!message) {
    return res.status(400).json({ error: "âŒ Ø§Ù„Ø±Ø³Ø§Ù„Ø© ÙØ§Ø±ØºØ©!" });
  }

  try {
    // ğŸ”¹ **Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø© (Thread)**
    const thread = await openai.beta.threads.create();

    // ğŸ”¹ **Ø¥Ø±Ø³Ø§Ù„ Ø±Ø³Ø§Ù„Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©**
    await openai.beta.threads.messages.create(thread.id, {
      role: "user",
      content: message,
    });

    // ğŸ”¹ **ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø¯**
    const run = await openai.beta.threads.runs.create(thread.id, {
      assistant_id: assistantId,
    });

    // ğŸ”¹ **Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©**
    let runStatus;
    do {
      await new Promise((resolve) => setTimeout(resolve, 2000)); // â³ Ø§Ù†ØªØ¸Ø§Ø± 2 Ø«Ø§Ù†ÙŠØ©
      runStatus = await openai.beta.threads.runs.retrieve(thread.id, run.id);
    } while (runStatus.status !== "completed");

    // ğŸ”¹ **Ø¬Ù„Ø¨ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ**
    const messages = await openai.beta.threads.messages.list(thread.id);
    const reply = messages.data[0].content[0].text.value;

    res.json({ reply });
  } catch (error) {
    console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ OpenAI API:", error);
    res.status(500).json({ error: "âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ OpenAI API" });
  }
}
